---
title: "Project:Energy Efficiency of Buildings"
author: "Pratap Timilsina"
date: "December 17, 2016"
output: html_document
---


# Library
```{r,echo=FALSE}

library(partykit)
library(class)
library (party)
library(corrplot)
library(car)
library(rpart)
library(rpart.plot)
library(rattle)
library(randomForest)
library(caret)

```

# Exploratory Analysis
```{r}

setwd("F:\\rockhurst\\02Applied Data Mining\\project\\Applied-Data-Mining")
House<-read.table("ecohome.csv",sep=",",head=T)


head(House)
tail(House)
View(House)
str(House)
summary(House)

Relative.Compactness <- House$X1 
Surface.Area <-House$X2 
Wall.Area <-House$X3
Roof.Area <-House$X4 
Overall.Height <- House$X5
Orientation <-House$X6
Glazing.Area  <-House$X7
Glazing.Area.Distribution <-House$X8 
Heating.Load <- House$Y1
Cooling.Load <- House$Y2

```

We are able to see the summary statistics of 8 input parameters and 2 output efficiency parameters.

#Correlation
```{r}

cor(House)
pairs(House)

```

The correlation between two output parameters  is very high (i.e. 0.975).Hence by studying one of the output parameter, we can predict the value of other output parameter. So we have considered Heating Load  as the only output parameter.  Overall Height  variable has a very good correlation with the output parameter Heating Load (i.e. 0.889), hence we can say that Overall Height  is good  predictor of output parameter Heating Load.  Also  Relative Compactness  has a good correlation with the output parameter, so it is also a good predictor of output parameter.  The two predictor variables also have good correlation with each other. So the two predictor variable can themselves act as a good predictor-output pair and similarly we can see other relation.
The correlation table results were accounted in linear model.

#Distribution of input parameters and output parameters
```{r}
par(mfrow=c(2,2))
hist(Relative.Compactness,col = "blue1")
hist(Surface.Area,col = "blue1")
hist(Wall.Area,col = "blue1") 
hist(Roof.Area,col = "blue1")
par(mfrow=c(2,2))
hist(Overall.Height,col = "blue1") 
hist(Orientation,col = "blue1") 
hist(Glazing.Area ,col = "blue1") 
hist(Glazing.Area.Distribution ,col = "blue1")
par(mfrow=c(2,1))
hist(Heating.Load,col = "blue1") 
hist(Cooling.Load,col = "blue1" )
House<-House[-10]

```


#Linear Model 1 with all Predictors
```{r}
House<-House[-10]
lm.mo1<-lm(Heating.Load~Relative.Compactness+Surface.Area+Wall.Area+Roof.Area+Overall.Height+Orientation
+Glazing.Area+Glazing.Area.Distribution,data=House)
summary(lm.mo1)

```

####When comparing models fitted by maximum likelihood to the same data, the smaller the AIC or BIC, the better the fit.

#Akaike Information Criterion (AIC)
```{r}
step (lm.mo1, direction="backward")

```

####After removing Roof Area the AIC remains unchanged. This happens due to the fact that Roof Area does not play a part in determining the response variable but after removing Orientation the model improves as AIC changes. We can see that attributes like Relative Compactness, Surface Area, Wall Area, Overall Height, Glazing Area and Glazing Area Distribution play a significant part in deciding the value of response variable.

#Bayesian Information Criterion (BIC)
```{r}
step(lm.mo1,direction="backward",k=log(nrow(House)))

```

####The behavior of BIC is similar to AIC.BIC  remains unchanged after removal of Roof Area since it is not significant in determining the value of response variable. The model improves after the removal of Orientation. Thus AIC and BIC give similar outputs and the significant variables remain the same for both.



### Examine the Residuals
####The residual for the final model is discussed later on. Residual plots is plotted for each model so as to compare how it changes.

```{r,echo=TRUE}
par(mfrow=c(2,2))
plot(lm.mo1)
```

#Linear Model with interaction between predictors
##Linear Model 2 
The interactin term Relative.Compactness:Overall.Height added to linear model 1.
We added interaction terms by seeing the correlation matrix.

```{r}
lm.mo2<-lm(Heating.Load~Relative.Compactness+Surface.Area+Wall.Area+Roof.Area+Overall.Height+Orientation
+Glazing.Area+Glazing.Area.Distribution+Relative.Compactness:Overall.Height,data=House)
summary(lm.mo2)

```


### Examine the Residuals

```{r,echo=TRUE}
par(mfrow=c(2,2))
plot(lm.mo2)

```

##Linear Model 3
The interactin term Glazing.Area.Distribution:Overall.Height added to linear model 2

```{r}
lm.mo3<-lm(Heating.Load~Relative.Compactness+Surface.Area+Wall.Area+Roof.Area+Overall.Height+Orientation
+Glazing.Area+Glazing.Area.Distribution+Relative.Compactness:Overall.Height+Glazing.Area.Distribution:Overall.Height,data=House)
summary(lm.mo3)

```


### Examine the Residuals

```{r,echo=TRUE}
par(mfrow=c(2,2))
plot(lm.mo3)


```

##Linear Model 4
The interactin term Surface.Area:Roof added to linear model 3

```{r}
lm.mo4<-lm(Heating.Load~Relative.Compactness+Surface.Area+Wall.Area+Roof.Area+Overall.Height+Orientation
+Glazing.Area+Glazing.Area.Distribution+Relative.Compactness:Overall.Height+Glazing.Area.Distribution:Overall.Height+Surface.Area:Roof.Area,data=House)
summary(lm.mo4)

```


### Examine the Residuals

```{r,echo=TRUE}
par(mfrow=c(2,2))
plot(lm.mo4)


```


##Linear Model 5
The interactin term Wall.Area:Overall.Height added to linear model 4

```{r}
lm.mo5<-lm(Heating.Load~Relative.Compactness+Surface.Area+Wall.Area+Roof.Area+Overall.Height+Orientation
+Glazing.Area+Glazing.Area.Distribution+Relative.Compactness:Overall.Height+Glazing.Area.Distribution:Overall.Height+Surface.Area:Roof.Area+Wall.Area:Overall.Height,data=House)
summary(lm.mo5)

```


### Examine the Residuals

```{r,echo=TRUE}
par(mfrow=c(2,2))
plot(lm.mo5)


```


##Linear Model 6

```{r}
lm.mo6<-lm(Heating.Load~Relative.Compactness+Surface.Area+Wall.Area+Roof.Area+Overall.Height+Orientation
+Glazing.Area+Glazing.Area.Distribution+Relative.Compactness:Overall.Height+Glazing.Area.Distribution:Overall.Height+Surface.Area:Roof.Area+Wall.Area:Overall.Height+Glazing.Area:Glazing.Area.Distribution,data=House)
summary(lm.mo6)

```

The R-squared value increases gradually from model1 to model6 indicating the performance of the model improved.

### Examine the Residuals

```{r,echo=TRUE}
par(mfrow=c(2,2))
plot(lm.mo6)


```


####The Residuals v/s Fitted values graph shows that the variables are scattered on the both side of the reference line. Also there is a very high variance in the values. This is due to the fact that most variables have few distinct values because of which the values in graph are scattered. Also the graph appears to be fanning out to the right. Hence the model is not a good fit for the data. The normal Q-Q graph is not linear, it is off at the ends of diagonal.



####	Are lm.mo and lm.mo5 significantly different? 
```{r}
anova(lm.mo1,lm.mo6)

```

#####The p-value of anova test <0.05 indicates that lm.mo6 is better that lm.mo1  ie lm.mo6 has statistically significant difference.


##Durbin Watson Test

```{r}
library(car)
durbinWatsonTest(lm.mo1)
durbinWatsonTest(lm.mo2)
durbinWatsonTest(lm.mo3)
durbinWatsonTest(lm.mo4)
durbinWatsonTest(lm.mo5)
durbinWatsonTest(lm.mo6)

#0<DW<2 implies autocorrelation in error terms
#DW=2 implies there is no autocorrelation in error terms
```

#####D-W Statistic = 0.6397252 , there is autocorrelation in error terms telling about we need to improve accuracy of model.


##Non-constant Variance Score Test

```{r}
ncvTest(lm.mo1)
ncvTest(lm.mo2)
ncvTest(lm.mo3)
ncvTest(lm.mo4)
ncvTest(lm.mo5)
ncvTest(lm.mo6)

```

#####The p-Value<0.05 for Non-constant Variance Score Test indicates heteroskedasticity meaning the probability distribution of the errors don't have constant variance. T


# Validation approach using 70-30 split
```{r}
splitdf <- function(dataframe, seed=NULL,percent_train=NULL) {
  if (!is.null(seed)) set.seed(seed)
  index <- 1:nrow(dataframe)
  trainindex <- sample(index, trunc(length(index)*percent_train/100))
  trainset <- dataframe[trainindex, ]
  testset <- dataframe[-trainindex, ]
  list(trainset=trainset,testset=testset)}
#apply the function
splits <- splitdf(House, seed=808,percent_train=70)
 

# save the training and testing sets as data frames
House_train <- splits$trainset
House_test <- splits$testset
dim(House_train) #checking the split
dim(House_test) #checking the split

```


# Tree
```{r}
library(partykit)
library(party)
library(rminer)
House.ctree<-ctree(House_train$Y1~.,  data=House_train)
House.ctree

actual <- House_test$Y1
House_predicted1 <- predict(House.ctree, newdata=House_test) 

mctree=mmetric(actual,House_predicted1 ,c("MAE","RMSE","MAPE","RMSPE","RAE","RRSE","COR","R2"))

House.rpart<-rpart(House_train$Y1~.,  data=House_train)
House.rpart
rpart.plot(House.rpart,digit=3,cex=.8,fallen.leaves=TRUE,type=3,extra=101)



#We are going to convert House.rpart to a party object using the partykit package.
#Then we will use the plot function in the party package to create a nicer
#looking tree.

House.party<-as.party(House.rpart)
plot(House.party)


actual <- House_test$Y1
House_predicted2 <- predict(House.rpart, newdata=House_test) 

mparty=mmetric(actual,House_predicted2 ,c("MAE","RMSE","MAPE","RMSPE","RAE","RRSE","COR","R2"))

a=cbind(mctree,mparty)
a

#MAE -- mean absolute error 
#RMSE -- root mean squared error
#MAPE -- Mean Absolute Percentage mmetric forecasting metric 
#RMSPE -- Root Mean Square Percentage mmetric forecasting metric 
#RAE -- relative absolute error
#RRSE -- root relative squared error
#COR -- correlation
#R2 -- coefficient of determination R^2 
#https://www.rdocumentation.org/packages/rminer/versions/1.4.1/topics/mmetric

```

The coefficient of determination/ goodness of fit for ctree is 99.12% and rtree is 95.01% . We prefer rtree  over ctree as rtree easy to follow and explain.

#Random Forest
```{r}
House<-House[-10]
set.seed(123)
rf.fit = randomForest(House$Y1~., data = House, mtry =8, ntree=500)
print(rf.fit)
plot(rf.fit)
rf.fit$importance
varImpPlot(rf.fit)

```

We are able to know the important parameter which can be used as knob for tuning the output efficiency parameter heating load.




